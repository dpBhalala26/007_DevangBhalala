# -*- coding: utf-8 -*-
"""3-linear-regression-numpy.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wzD5jx6a6Kc3n2RJhv1Y_U10rPx6ndyz

#Exercise 1:
 Try Linear Regression just using numpy (Without Tensorflow/Pytorch or other torch library). You can optionally use sklearn (if you want)
"""

# Import Numpy
import numpy as np

"""## Linear Regression Model using numpy

Re-implementing the same model using numpy using two different targets: Apples and Oranges
"""

# Input (temp, rainfall, humidity)
inputs = np.array([[73, 67, 43], [91, 88, 64], [87, 134, 58], [102, 43, 37], [69, 96, 70], [73, 67, 43], [91, 88, 64], [87, 134, 58], [102, 43, 37], [69, 96, 70], [73, 67, 43], [91, 88, 64], [87, 134, 58], [102, 43, 37], [69, 96, 70]], dtype='float32')
# Targets (apples, oranges)
targets = np.array([[56, 70], [81, 101], [119, 133], [22, 37], [103, 119], 
                    [56, 70], [81, 101], [119, 133], [22, 37], [103, 119], 
                    [56, 70], [81, 101], [119, 133], [22, 37], [103, 119]], dtype='float32')

# getting x-shape

x_shape = inputs.shape
print(x_shape)

"""Getting Random Weights and biases"""

weights = np.random.rand(2,3)
weights

biases = np.random.rand(15,2)
biases

"""Linear Regression Model"""

# Define the model

def model(x):
    return x @ np.transpose(weights) + biases

# Generate predictions

preds = model(inputs)
print(preds)

# Compare with targets

print(targets)

"""# Loss Function

We can compare the predictions with the actual targets, using the following method: 
* Calculate the difference between the two matrices (`preds` and `targets`).
* Square all elements of the difference matrix to remove negative values.
* Calculate the average of the elements in the resulting matrix.

The result is a single number, known as the **mean squared error** (MSE).
"""

# MSE loss

def mse(t1, t2):
    diff = t1 - t2
    return np.sum(diff * diff) / len(diff)

# Compute loss

loss = mse(preds, targets)
print(loss)

"""# Compute Gradiants

Gradiants for weights
"""

weights_grad = (np.matmul(np.transpose((preds-targets)),inputs))*2/x_shape[0]
weights_grad

"""Gradiants for biases"""

biases_grad = (preds-targets)*2/x_shape[0]
biases_grad

"""# Adjust Weights using Gradints"""

weights -= weights_grad * 1e-5
weights

biases -= biases_grad * 1e-5
biases

"""Calculate Loss"""

preds = model(inputs)
loss = mse(preds, targets)
print(loss)

for i in range(200):
    preds = model(inputs)
    loss = mse(preds, targets)
    
    biases_grad = ((((inputs@np.transpose(weights))+biases)-targets))*2/x_shape[0]
    weights_grad = (np.matmul(np.transpose((((inputs@np.transpose(weights))+biases)-targets)),inputs))*2/x_shape[0]

    weights -= weights_grad * 1e-5
    biases -= biases_grad * 1e-5

"""Calculate Loss"""

preds = model(inputs)
loss = mse(preds, targets)
print(loss)

"""Printing Predictions"""

preds

"""Compare with targets"""

targets